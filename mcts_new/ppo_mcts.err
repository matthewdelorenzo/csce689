Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]
Some weights of the model checkpoint at /mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b were not used when initializing LlamaForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b', and no v_head weight is found. This IS expected if you are not resuming PPO training.
Traceback (most recent call last):
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/research/mcts_new/main.py", line 127, in <module>
    model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/trl/models/modeling_base.py", line 321, in from_pretrained
    filename = hf_hub_download(
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b'. Use `repo_type` argument if needed.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]
Some weights of the model checkpoint at /mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b were not used when initializing LlamaForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b', and no v_head weight is found. This IS expected if you are not resuming PPO training.
Traceback (most recent call last):
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/research/mcts_new/main.py", line 127, in <module>
    model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/trl/models/modeling_base.py", line 321, in from_pretrained
    filename = hf_hub_download(
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b'. Use `repo_type` argument if needed.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]
Some weights of the model checkpoint at /mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b were not used when initializing LlamaForCausalLM: ['v_head.summary.weight', 'v_head.summary.bias']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b', and no v_head weight is found. This IS expected if you are not resuming PPO training.
Traceback (most recent call last):
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/research/mcts_new/main.py", line 127, in <module>
    model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/trl/models/modeling_base.py", line 321, in from_pretrained
    filename = hf_hub_download(
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b'. Use `repo_type` argument if needed.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
Some weights of the model checkpoint at /mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b were not used when initializing LlamaForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b', and no v_head weight is found. This IS expected if you are not resuming PPO training.
Traceback (most recent call last):
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/research/mcts_new/main.py", line 127, in <module>
    model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/trl/models/modeling_base.py", line 321, in from_pretrained
    filename = hf_hub_download(
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b'. Use `repo_type` argument if needed.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.22s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]
Some weights of the model checkpoint at /mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b were not used when initializing LlamaForCausalLM: ['v_head.summary.weight', 'v_head.summary.bias']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b', and no v_head weight is found. This IS expected if you are not resuming PPO training.
Traceback (most recent call last):
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/research/mcts_new/main.py", line 127, in <module>
    model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/trl/models/modeling_base.py", line 321, in from_pretrained
    filename = hf_hub_download(
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b'. Use `repo_type` argument if needed.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.14s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]
Some weights of the model checkpoint at /mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b were not used when initializing LlamaForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']
- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b', and no v_head weight is found. This IS expected if you are not resuming PPO training.
Traceback (most recent call last):
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/research/mcts_new/main.py", line 127, in <module>
    model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/trl/models/modeling_base.py", line 321, in from_pretrained
    filename = hf_hub_download(
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/miniconda3/envs/rltf/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/mnt/shared-scratch/Rajendran_J/matthewdelorenzo/rltf/ppo_codellama13b'. Use `repo_type` argument if needed.
